<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Real-Time Deepfake Detection in the Real-World"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="https://vision.huji.ac.il/ladeda/">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Real-Time Deepfake Detection in the Real-World</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <style>
    .video-container {
      position: relative;
      width: 100%;
      max-width: 800px;
      margin: auto;
      border: 10px solid #ddd;
      border-radius: 15px;
      overflow: hidden;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }

    video {
      width: 100%;
      height: auto;
      display: block;
    }
  </style>

<style>
  .hero.is-custom-color {
    background-color: #a3cadb33; /* Replace with your desired color */
  }
</style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero is-small is-custom-color">
    <div class="hero-body">
      <div class="container is-max-desktop has-text-centered">
        <h1 class="title is-1 publication-title">Real-Time Deepfake Detection in the Real-World</h1>
        <div class="is-size-5 publication-authors">
          <span class="author-block"><a href="https://www.linkedin.com/in/bar-cavia/" target="_blank">Bar Cavia</a>,</span>
          <span class="author-block"><a href="https://pages.cs.huji.ac.il/eliahu-horwitz/" target="_blank">Eliahu Horwitz</a>,</span>
          <span class="author-block"><a href="https://scholar.google.com/citations?user=sgMIT6EAAAAJ&hl=en" target="_blank">Tal Reiss</a>,</span>
          <span class="author-block"><a href="https://cs.huji.ac.il/w~ydidh/" target="_blank">Yedid Hoshen</a></span>
        </div>
        <div class="is-size-5 publication-authors">
          <span class="author-block">The Hebrew University of Jerusalem<br></span>
        </div>
        <div class="publication-links">
          <span class="link-block">
            <a href="https://arxiv.org/pdf/2406.09398.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
              <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://github.com/barcavia/RealTime-DeepfakeDetection-in-the-RealWorld" target="_blank" class="external-link button is-normal is-rounded is-dark">
              <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://arxiv.org/abs/2406.09398" target="_blank" class="external-link button is-normal is-rounded is-dark">
              <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </section>

  <div class="hr">
    <div class="container">
      <hr class="is-custom-color">
    </div>
  </div>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered" style="font-size: 1.5rem;">Locally Aware Deepfake Detection Algorithm (<em>LaDeDa</em>)</h2>
      <div class="video-container">
        <video poster="" id="tree" autoplay controls muted loop height="90%">
        <!-- Your video here -->
          <source src="static/videos/LaDeDa_vid.mp4" type="video/mp4">
        </video>
      </div>
      <h2 class="subtitle has-text-centered">
        By limiting its receptive field to qxq pixels, <em>LaDeDa</em> yields a deepfake score for each qxq patch. The image-level deepfake score is the global pooling of the patches scores. We use binary cross entropy loss between the image label and its deepfake score.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent improvements in generative AI made synthesizing fake images easy; as they can be used to cause harm, it is crucial to develop accurate techniques to identify them. This paper introduces "Locally Aware Deepfake Detection Algorithm" (<em>LaDeDa</em>), that accepts a single 9x9 image patch and outputs its deepfake score. The image deepfake score is the pooled score of its patches. With merely patch-level information, LaDeDa significantly improves over the state-of-the-art, achieving around 99\% mAP on current benchmarks. Owing to the patch-level structure of LaDeDa, we hypothesize that the generation artifacts can be detected by a simple model. We therefore distill LaDeDa into Tiny-LaDeDa, a highly efficient model consisting of only 4 convolutional layers. Remarkably, Tiny-LaDeDa has 375x fewer FLOPs and is 10,000x more parameter-efficient than LaDeDa, allowing it to run efficiently on edge devices with a minor decrease in accuracy. These almost-perfect scores raise the question: is the task of deepfake detection close to being solved?  Perhaps surprisingly, our investigation reveals that current training protocols prevent methods from generalizing to real-world deepfakes extracted from social media. To address this issue, we introduce <em>WildRF</em>, a new deepfake detection dataset curated from several popular social networks. Our method achieves the top performance of 93.7% mAP on WildRF, however the large gap from perfect accuracy shows that reliable real-world deepfake detection is still unsolved.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Tiny-LaDeDa</h2>
          <div class="level-set has-text-justified">
            <p>
              Since LaDeDa focuses on small patches, we hypothesized that a very simple model may be sufficient for detecting deepfake artifacts. We therefore designed Tiny-LaDeDa, a highly efficient model consisting of only 4 convolutional layers.
              Remarkably, Tiny-LaDeDa achieves superior compute efficiency compared to other SoTA methods with minor accuracy trade-off.
            </p>
          </div>
          <div class="columns">
            <div class="column">
              <img src="static/images/Tiny.png" alt="Tiny-LaDeDa" class="blend-img-background center-image" style="width: 85%; height: auto;" />
              <p>
              <em><strong>Tiny-LaDeDa Distillation.</strong></em> To train Tiny-LaDeDa we perform logit-based distillation using the patch-level deepfake scores predicted by LaDeDa (the teacher).
              </p>
            </div>

            <div class="column">
              <img src="static/images/FLOPs_vs_AP_updated.png" alt="" class="blend-img-background center-image" style="width: 85%; height: auto;" />
              <em><strong>Performance vs. Efficiency trade-off.</strong></em> SoTA methods comparison of average precision (AP) performance on real-world data as a function of floating point operations per second (FLOPs) at inference time.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Aligning Deepfake Evaluation with the Real-World</h2>
          <div class="level-set has-text-justified">
            <p>
              With LaDeDa and Tiny-LaDeDa achieving near-perfect scores on current deepfake detection benchmarks, one could ask if the task is close to being solved.
              However, we found that standard training protocols prevent SoTA methods (including ours) to detect real-world deepfakes, taken from popular social platforms. To tackle this, we introduce <em>WildRF</em>, a new deepfake detection dataset curated from popular social networks: Reddit, X (Twitter) and Facebook. We validated WildRF's effectiveness by retraining SoTA methods on this real-world data, significantly improving their performance compared to training with standard protocols.
            </p>
          </div>
          <div class="column">
            <img src="static/images/WildRF_no_background.png" alt="WildRF" class="blend-img-background center-image" style="max-width: 85%; height: auto; margin-left: 55px;" />
            <p>
            <em><strong>WildRF Overview.</strong></em> A realistic benchmark consisting of images sourced from popular social platforms: Reddit, X (Twitter) and Facebook. WildRF captures high variability in a range of attributes including image resolutions, formats, semantic content, generation techniques and edits encountered in-the-wild.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Coming soon</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
